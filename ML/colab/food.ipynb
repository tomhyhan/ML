{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML6jOXHxaxvVDywUHDwDmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomhyhan/ML/blob/main/ML/colab/food.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmPzoiNd3KHm"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import torchvision\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import Subset, random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6LYAFj7wHBge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    transform = tt.Compose([\n",
        "        tt.Resize(256),\n",
        "        tt.CenterCrop(224),\n",
        "        tt.ToTensor(),\n",
        "        tt.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    food101_data =torchvision.datasets.Food101(download=True, root=\"./\", transform=transform)\n",
        "    print(\"transform done\")\n",
        "    subset_indices = set()\n",
        "    subset_images = []\n",
        "    for i in range(len(food101_data)):\n",
        "        if i % 1000 == 0:\n",
        "            print(\"iter: \", i)\n",
        "            print(subset_indices)\n",
        "        subset_indices.add(food101_data[i][1])\n",
        "        subset_images.append(i)\n",
        "        if len(subset_indices) > 20:\n",
        "            break\n",
        "    food101_subset = Subset(food101_data, subset_images)\n",
        "    print(\"len: \", len(food101_subset))\n",
        "    traning_i = int(len(food101_subset) * 0.9)\n",
        "    test_i = len(food101_subset) - traning_i\n",
        "    f_train, f_test = random_split(food101_subset, [traning_i, test_i])\n",
        "    return f_train, f_test\n",
        "\n",
        "f_train, f_test = load_data()\n",
        "print(len(f_train), len(f_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN6qSzdc3PCr",
        "outputId": "da75a021-5130-4d01-cf53-c4b767919895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transform done\n",
            "iter:  0\n",
            "set()\n",
            "iter:  1000\n",
            "{54, 23}\n",
            "iter:  2000\n",
            "{85, 54, 23}\n",
            "iter:  3000\n",
            "{86, 85, 54, 23}\n",
            "iter:  4000\n",
            "{77, 23, 85, 86, 54, 92}\n",
            "iter:  5000\n",
            "{73, 77, 23, 85, 86, 54, 92}\n",
            "iter:  6000\n",
            "{4, 73, 77, 23, 85, 86, 54, 92}\n",
            "iter:  7000\n",
            "{4, 39, 73, 77, 48, 23, 85, 86, 54, 92}\n",
            "iter:  8000\n",
            "{96, 4, 39, 73, 77, 48, 23, 85, 86, 54, 92}\n",
            "iter:  9000\n",
            "{96, 4, 70, 39, 73, 77, 48, 23, 85, 86, 54, 92}\n",
            "iter:  10000\n",
            "{96, 4, 70, 39, 73, 77, 78, 48, 81, 23, 85, 86, 54, 92}\n",
            "iter:  11000\n",
            "{96, 4, 70, 39, 73, 77, 78, 48, 81, 80, 23, 85, 86, 54, 92}\n",
            "iter:  12000\n",
            "{96, 4, 70, 39, 7, 73, 77, 78, 48, 81, 80, 23, 85, 86, 54, 92}\n",
            "iter:  13000\n",
            "{96, 0, 4, 70, 39, 7, 73, 6, 77, 78, 48, 81, 80, 23, 85, 86, 54, 92}\n",
            "iter:  14000\n",
            "{0, 4, 6, 7, 23, 26, 39, 48, 54, 70, 73, 77, 78, 80, 81, 85, 86, 92, 96}\n",
            "iter:  15000\n",
            "{0, 4, 6, 7, 23, 26, 39, 48, 54, 70, 73, 77, 78, 80, 81, 84, 85, 86, 92, 96}\n",
            "len:  15001\n",
            "13500 1501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 5\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "w9Oq8_MoNoUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(CNN, self).init()\n",
        "      self.build_net()\n",
        "\n",
        "    def build_net(self):\n",
        "        self.dropout = 0.5\n",
        "        # Sizes\n",
        "        # image: (batch_size, 3, 224, 224)\n",
        "        # Conv: (batch_size, 32, 220, 220)\n",
        "        # Pool: (batch_size, 32, 110, 110)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Sizes\n",
        "        # image: (batch_size, 32, 109, 109)\n",
        "        # Conv: (batch_size, 64, 105, 105)\n",
        "        # Pool: (batch_size, 64, 52, 52)\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Sizes\n",
        "        # image: (batch_size, 64, 52, 52)\n",
        "        # Conv: (batch_size, 128, 48, 48)\n",
        "        # Pool: (batch_size, 128, 24, 24)\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(128* 24 * 24, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout)\n",
        "        )\n",
        "        self.fc2 = nn.Linear(512, 20)\n",
        "\n",
        "        self.cost_fn = nn.CrossEntropyLoss()\n",
        "        self.optimizer = t.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(x)\n",
        "        out = self.conv3(x)\n",
        "        out = self.view(out.size(0), -1)\n",
        "        out = self.fc1(x)\n",
        "        out = self.fc2(x)\n",
        "        return out\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.eval()\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "0Db81VkGHb1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.cuda.is_available()\n",
        "print(len(f_train))\n",
        "print(f_train[0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R92N9XQh4ors",
        "outputId": "45175a7d-7495-4ebd-b0d0-849646c8c91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13500\n",
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = t.randn(20, 16, 50, 32)\n",
        "print(t.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "-ZgOG5vBRPCB",
        "outputId": "aff7bcb0-47be-4589-dedd-53ed8e00db8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Tensor' object has no attribute 'randn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7bc850ec91b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'randn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "train_loader = DataLoader(f_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(f_test, batch_size=len(f_test), shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3YfYduB4vpt",
        "outputId": "9b64ecf0-4c3e-432c-fd55-484c62b9535d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13500\n"
          ]
        }
      ]
    }
  ]
}